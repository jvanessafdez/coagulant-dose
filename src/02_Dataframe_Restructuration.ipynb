{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "009801b1",
   "metadata": {},
   "source": [
    "# Reestructuración y limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bbfe55",
   "metadata": {},
   "source": [
    "Este cuaderno se encarga de la reestructuración y limpieza de los datos. Los pasos que sigue son los siguientes:\n",
    "\n",
    "1. **Lectura de datos**: Se importan las bibliotecas necesarias y se cargan los dataframes previamente creados, tanto el que contiene los datos originales como el que contiene los datos editados.\n",
    "\n",
    "\n",
    "2. **Organización del DataFrame**: Se realiza una serie de transformaciones en los dataframes para organizarlos y hacerlos más manejables. Esto incluye la unificación de las columnas de multiindex en un solo index, el reemplazo de los espacios en blanco por guiones bajos en los nombres de las columnas, la renombración de algunas columnas para una mejor interpretación y la conversión de todos los nombres de las columnas a mayúsculas.\n",
    "\n",
    "\n",
    "3. **Transformación y limpieza de Datos**: Se convierten los datos en las columnas 'FECHA' y 'HORA' a sus respectivos tipos de datos. Además, se implementa una función para eliminar la hora cero de los datframes, puesto que, se cuenta con la hora 24. Durante esta, notamos que había datos mal escritos, por ejemplo, se encontraron valores como 2,.4 o 4. o 2,4* o 2, 4. Para resolver esta situación, se eliminaron los símbolos, espacios y otros caracteres que interferían con la conversión del dato en un número válido, ya sea flotante o entero. Aquellos datos que no pudieron ser convertidos se registraron como NaN y luego se convierten a tipo float. Por indicaciones dadas por el ingeniero Mauricio los datos de dosis de coagulante que tuvieran decimales se deben redondear hacia abajo al entero más cercano.\n",
    "\n",
    "\n",
    "4. **Evaluación del relleno manual**: Siguiendo las especificaciones proporcionadas por el ingeniero Mauricio, se llevó a cabo un rellenado manual en los archivos de Excel correspondientes a los años 2013 al 2020. Si había espacios entre datos de un mismo día, se completaba con la dosis de coagulante anterior más cercana, siempre que los datos de agua cruda fueran muy similares. En caso contrario, si la turbiedad era menor o igual a 3, se rellenaba con cero. Además, se estableció que si un día completo estaba vacío y el valor de turbiedad cruda era menor o igual a 3, la dosis de coagulante debía ser cero. Para los años 2021 y 2022, el ingeniero Mauricio indicó que se debería coagular siempre en las noches y coagular durante el día únicamente si la turbiedad era mayor a 3. Por lo tanto, se creó una función `reemplazar_nan` para evaluar y rectificar el llenado manual realizado previamente y se aplicó el proceso de rellenado para los años 2021 y 2022.\n",
    "\n",
    "\n",
    "5. **Creación de CSV:** Al final del proceso, se guardan los dataframes reestructurados y limpios en archivos CSV para su posterior análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144ccf98",
   "metadata": {},
   "source": [
    "## 1. Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da87768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de bibliotecas necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dadbdd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lectura de dataframes\n",
    "df = pd.read_csv('../data/dataframe.csv',sep=',', encoding='latin-1', header=[0, 1], index_col=0, low_memory=False)\n",
    "# df_edit = pd.read_csv('../data_edit/dataframe_edit.csv',sep=',', encoding='latin-1', header=[0, 1], index_col=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d25264",
   "metadata": {},
   "source": [
    "## 2. Organización del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9b3bcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_order(df):\n",
    "    # Une columnas multi-index en un solo índice con guión bajo ('_').\n",
    "    df.columns = df.columns.map('_'.join)\n",
    "\n",
    "    # Reemplaza espacios en nombres de columnas por guiones bajos.\n",
    "    df.columns = [col.replace(' ', '_') for col in df.columns]\n",
    "\n",
    "    # Renombra algunas columnas para una mejor comprensión.\n",
    "    df = df.rename(columns={'FECHA_Unnamed:_1_level_1': 'FECHA', 'HORA_Unnamed:_2_level_1': 'HORA','CAUDAL_Entr_l/s':'CAUDAL','Cal_1ria_Kg.':'Cal_1ria_Kg'})\n",
    "\n",
    "    # Convierte todos los nombres de columnas a mayúsculas.\n",
    "    df.columns = df.columns.str.upper()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda57821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica la función df_order a ambos DataFrames.\n",
    "df = df_order(df)\n",
    "# df_edit = df_order(df_edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e83905",
   "metadata": {},
   "source": [
    "## 3. Transformación y limpieza de Datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00aedf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranformación de columnas 'CAUDAL', 'HORA' y 'FECHA'\n",
    "def convert_data(df):\n",
    "    # Conversión de datos de FECHA y HORA\n",
    "    # Convierte 'FECHA' a formato datetime y 'HORA' a int\n",
    "    df['FECHA'] = pd.to_datetime(df['FECHA'], format='%d/%m/%Y')\n",
    "    df['HORA'] = df['HORA'].astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b698d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica la función convert_data en ambos DataFrames\n",
    "df = convert_data(df)\n",
    "# df_edit = convert_data(df_edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c0cf43",
   "metadata": {},
   "source": [
    "## 4. Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "504d0e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de hora cero\n",
    "def del_hour_zero(df):\n",
    "    # Filtra las filas donde 'HORA' es distinto de cero\n",
    "    filtro_hora = df['HORA'] != 0\n",
    "    df = df[filtro_hora]\n",
    "    \n",
    "    # Resetea el índice del DataFrame\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eb32bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica la función del_hour_zero en ambos DataFrames\n",
    "df = del_hour_zero(df)\n",
    "# df_edit = del_hour_zero(df_edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43b88da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza de celdas\n",
    "def cell_clean(cell):\n",
    "    # Reemplaza 'NO HAY AGUA' por 0\n",
    "    if isinstance(cell, str) and cell.strip().upper() == 'NO HAY AGUA':\n",
    "        return 0\n",
    "\n",
    "    # Verifica si la celda contiene un valor NaN. Si la celda es NaN, la retorna tal cual\n",
    "    if pd.isna(cell):\n",
    "        return cell\n",
    "\n",
    "    # Buscar y eliminar caracteres no deseados (solo conserva números y puntos)\n",
    "    cell = cell.replace(',', '.')\n",
    "    cell_cleaned = re.sub(r'[^0-9.]', '', str(cell))\n",
    "\n",
    "    # Convertir la celda a un número si es posible, de lo contrario, devuelve un NaN\n",
    "    try:\n",
    "        return float(cell_cleaned) if '.' in cell_cleaned else int(cell_cleaned)\n",
    "    except ValueError:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9e03ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicación de función anterior\n",
    "def apply_clean(df):\n",
    "    columns_object = df.select_dtypes(include='object').columns\n",
    "    df[columns_object] = df[columns_object].applymap(cell_clean)\n",
    "    \n",
    "    # Transformación de columnas limpias a float\n",
    "    df[columns_object] = df[columns_object].astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b7aaf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicación de función apply_clean en ambos Dataframes\n",
    "df = apply_clean(df)\n",
    "# df_edit = apply_clean(df_edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f800f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redondeo hacia abajo al entero más cercano\n",
    "def round_coagulant(df):\n",
    "    df['COAGULANTE_DOSIS'] = df['COAGULANTE_DOSIS'].apply(lambda x: math.floor(x) if pd.notnull(x) else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcb131d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_edit.loc[df['AGUA_TRATADA_P.H'] > 14, 'AGUA_TRATADA_P.H'] = df_edit.loc[df['AGUA_TRATADA_P.H'] > 14, 'AGUA_TRATADA_P.H'] / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e8ec767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicación de función round_coagulant en ambos Dataframes\n",
    "df = round_coagulant(df)\n",
    "# df_edit = round_coagulant(df_edit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51151b7b",
   "metadata": {},
   "source": [
    "## 5. Evaluación del relleno manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "458847e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectify_coagulant_dosis(df):\n",
    "    # Crea un DataFrame para los años 2021 y 2022\n",
    "    df_2021_2022 = df[(df['FECHA'].dt.year == 2021) | (df['FECHA'].dt.year == 2022)]\n",
    "\n",
    "    # Si la turbidez es <= 3 y la hora está entre las 8 y las 20, entonces la dosis de coagulante es 0\n",
    "    condition = (df_2021_2022['COAGULANTE_DOSIS'].isnull()) & (df_2021_2022['AGUA_CRUDA_NTU'] < 3) & (df_2021_2022['HORA'].between(8, 20))\n",
    "    df_2021_2022.loc[condition, 'COAGULANTE_DOSIS'] = 0\n",
    "\n",
    "    # Crea un DataFrame para los años distintos a 2021 y 2022\n",
    "    df_other_years = df[(df['FECHA'].dt.year != 2021) & (df['FECHA'].dt.year != 2022)]\n",
    "    condition = (df_other_years['COAGULANTE_DOSIS'].isnull()) & (df_other_years['AGUA_CRUDA_NTU'] < 3)\n",
    "    df_other_years.loc[condition, 'COAGULANTE_DOSIS'] = 0\n",
    "\n",
    "    # Combina los dos dataframes\n",
    "    df = pd.concat([df_other_years,df_2021_2022])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50ce089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicación de función relleno sólo al dataframe editado\n",
    "df_edit = rectify_coagulant_dosis(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbcb40c",
   "metadata": {},
   "source": [
    "## 6. Creación de CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f21cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de CSV\n",
    "df.to_csv('../data/dataframe_clean.csv', sep=',')\n",
    "df_edit.to_csv('../data_edit/dataframe_edit_clean.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c26676b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87648 entries, 0 to 87647\n",
      "Data columns (total 18 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   FECHA                     87648 non-null  datetime64[ns]\n",
      " 1   HORA                      87648 non-null  int32         \n",
      " 2   CAUDAL                    87380 non-null  float64       \n",
      " 3   CAL_1RIA_KG               29 non-null     float64       \n",
      " 4   CAL_1RIA_DOSIS            587 non-null    float64       \n",
      " 5   AGUA_CRUDA_P.H            86715 non-null  float64       \n",
      " 6   AGUA_CRUDA_COLOR          81227 non-null  float64       \n",
      " 7   AGUA_CRUDA_NTU            86984 non-null  float64       \n",
      " 8   AGUA_CRUDA_ALCALINIDAD    68371 non-null  float64       \n",
      " 9   AGUA_CRUDA_CONDUCTIVIDAD  60089 non-null  float64       \n",
      " 10  COAGULANTE_GRANULADO      5897 non-null   float64       \n",
      " 11  COAGULANTE_LIQUIDO        135 non-null    float64       \n",
      " 12  COAGULANTE_DOSIS          44393 non-null  float64       \n",
      " 13  AGUA_TRATADA_CLORO        77295 non-null  float64       \n",
      " 14  AGUA_TRATADA_ALCALINIDAD  36156 non-null  float64       \n",
      " 15  AGUA_TRATADA_P.H          84597 non-null  float64       \n",
      " 16  AGUA_TRATADA_COLOR        78538 non-null  float64       \n",
      " 17  AGUA_TRATADA_NTU          84771 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(16), int32(1)\n",
      "memory usage: 11.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d54c183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 87648 entries, 0 to 87647\n",
      "Data columns (total 18 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   FECHA                     87648 non-null  datetime64[ns]\n",
      " 1   HORA                      87648 non-null  int32         \n",
      " 2   CAUDAL                    87380 non-null  float64       \n",
      " 3   CAL_1RIA_KG               29 non-null     float64       \n",
      " 4   CAL_1RIA_DOSIS            587 non-null    float64       \n",
      " 5   AGUA_CRUDA_P.H            86715 non-null  float64       \n",
      " 6   AGUA_CRUDA_COLOR          81227 non-null  float64       \n",
      " 7   AGUA_CRUDA_NTU            86984 non-null  float64       \n",
      " 8   AGUA_CRUDA_ALCALINIDAD    68371 non-null  float64       \n",
      " 9   AGUA_CRUDA_CONDUCTIVIDAD  60089 non-null  float64       \n",
      " 10  COAGULANTE_GRANULADO      5897 non-null   float64       \n",
      " 11  COAGULANTE_LIQUIDO        135 non-null    float64       \n",
      " 12  COAGULANTE_DOSIS          78992 non-null  float64       \n",
      " 13  AGUA_TRATADA_CLORO        77295 non-null  float64       \n",
      " 14  AGUA_TRATADA_ALCALINIDAD  36156 non-null  float64       \n",
      " 15  AGUA_TRATADA_P.H          84597 non-null  float64       \n",
      " 16  AGUA_TRATADA_COLOR        78538 non-null  float64       \n",
      " 17  AGUA_TRATADA_NTU          84771 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(16), int32(1)\n",
      "memory usage: 12.4 MB\n"
     ]
    }
   ],
   "source": [
    "df_edit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5bcdba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
